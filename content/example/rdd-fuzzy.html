---
title: "Fuzzy regression discontinuity"
linktitle: "Fuzzy regression discontinuity"
date: "2020-10-28"
output:
  blogdown::html_page:
    toc: true
menu:
  example:
    parent: Examples
    weight: 11
type: docs
editor_options: 
  chunk_output_type: console
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />

<div id="TOC">
<ul>
<li><a href="#program-background">Program background</a></li>
<li><a href="#noncompliance-around-a-cutoff">Noncompliance around a cutoff</a></li>
<li><a href="#visualizing-a-fuzzy-gap">Visualizing a fuzzy gap</a></li>
<li><a href="#measuring-a-fuzzy-gap">Measuring a fuzzy gap</a>
<ul>
<li><a href="#fuzzy-parametric-estimation">Fuzzy parametric estimation</a></li>
<li><a href="#fuzzy-nonparametric-estimation">Fuzzy nonparametric estimation</a></li>
</ul></li>
</ul>
</div>

<div id="program-background" class="section level2">
<h2>Program background</h2>
<p>In this example, we’ll use the same situation that we used in the <a href="/example/rdd/">the example for regression discontinuity</a>:</p>
<ul>
<li>Students take an entrance exam at the beginning of the school year</li>
<li>If they score 70 or below, they are enrolled in a free tutoring program</li>
<li>Students take an exit exam at the end of the year</li>
</ul>
<p>If you want to follow along, download this dataset and put it in a folder named <code>data</code>:</p>
<ul>
<li><a href="/data/tutoring_program_fuzzy.csv"><i class="fas fa-table"></i> <code>tutoring_program_fuzzy.csv</code></a></li>
</ul>
<pre class="r"><code>library(tidyverse)  # ggplot(), %&gt;%, mutate(), and friends
library(broom)  # Convert models to data frames
library(rdrobust)  # For robust nonparametric regression discontinuity
library(estimatr)  # Run 2SLS models in one step with iv_robust()
library(modelsummary)  # Create side-by-side regression tables
library(kableExtra)  # Fancy table formatting

tutoring &lt;- read_csv(&quot;data/tutoring_program_fuzzy.csv&quot;)</code></pre>
</div>
<div id="noncompliance-around-a-cutoff" class="section level2">
<h2>Noncompliance around a cutoff</h2>
<p>In <a href="/example/rdd/">the example for regression discontinuity</a>, it was fairly easy to measure the size of the jump at the cutoff because compliance was perfect. No people who scored above the threshold used the tutoring program, and nobody who qualified for the program didn’t use it. It was a <em>sharp</em> design, since program usage looked like this:</p>
<p><img src="/example/rdd_files/figure-html/check-fuzzy-sharp-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>However, seeing a cutoff this sharp and this perfect is fairly rare. It is possible that some people scored higher on the entrace exam and somehow used tutoring, or that some people scored below the threshold but didn’t participate in the program, either because they’re never-takers, or because they fell through bureaucratic cracks.</p>
<p>More often, you’ll see compliance that looks like this:</p>
<pre class="r"><code>ggplot(tutoring, aes(x = entrance_exam, y = tutoring_text, color = entrance_exam &lt;= 70)) +
  # Make points small and semi-transparent since there are lots of them
  geom_point(size = 1.5, alpha = 0.5, 
             position = position_jitter(width = 0, height = 0.25, seed = 1234)) + 
  # Add vertical line
  geom_vline(xintercept = 70) + 
  # Add labels
  labs(x = &quot;Entrance exam score&quot;, y = &quot;Participated in tutoring program&quot;) + 
  # Turn off the color legend, since it&#39;s redundant
  guides(color = FALSE)</code></pre>
<p><img src="/example/rdd-fuzzy_files/figure-html/fuzzy-compliance-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>We can see the count and percentages of compliance with <code>group_by()</code> and <code>summarize()</code>:</p>
<pre class="r"><code>tutoring %&gt;% 
  group_by(tutoring, entrance_exam &lt;= 70) %&gt;% 
  summarize(count = n()) %&gt;% 
  group_by(tutoring) %&gt;% 
  mutate(prop = count / sum(count))</code></pre>
<pre><code>## # A tibble: 4 x 4
## # Groups:   tutoring [2]
##   tutoring `entrance_exam &lt;= 70` count   prop
##   &lt;lgl&gt;    &lt;lgl&gt;                 &lt;int&gt;  &lt;dbl&gt;
## 1 FALSE    FALSE                   646 0.947 
## 2 FALSE    TRUE                     36 0.0528
## 3 TRUE     FALSE                   116 0.365 
## 4 TRUE     TRUE                    202 0.635</code></pre>
<p>Here we have 36 people who should have used tutoring who didn’t (either because they’re never-takers and are anti-program, or because the system failed them), and we have 116 people (!!!) who somehow snuck into the program. That should probably be a big red flag for the program administrators. That means that 36.5% of people in the tutoring program shouldn’t have been there. Big yikes.</p>
<p>This is definitely not a sharp design. This is a fuzzy regression discontinuity.</p>
</div>
<div id="visualizing-a-fuzzy-gap" class="section level2">
<h2>Visualizing a fuzzy gap</h2>
<p>With regular sharp RD, our goal is to measure the size of the gap or discontinuity in outcome right at the cutoff. <a href="/example/rdd/#step-4-check-for-discontinuity-in-outcome-across-running-variabl">In our sharp example</a> we did this with different parametric regression models, as well as with the <code>rdrobust()</code> function for nonparametric measurement.</p>
<p>Regular parametric regression won’t really work here because we have strange compliance issues:</p>
<pre class="r"><code>ggplot(tutoring, aes(x = entrance_exam, y = exit_exam, color = tutoring)) +
  geom_point(size = 1, alpha = 0.5) + 
  # Add a line based on a linear model for the people scoring less than 70
  geom_smooth(data = filter(tutoring, entrance_exam &lt;= 70), method = &quot;lm&quot;) +
  # Add a line based on a linear model for the people scoring 70 or more
  geom_smooth(data = filter(tutoring, entrance_exam &gt; 70), method = &quot;lm&quot;) +
  geom_vline(xintercept = 70) +
  labs(x = &quot;Entrance exam score&quot;, y = &quot;Exit exam score&quot;, color = &quot;Used tutoring&quot;)</code></pre>
<p><img src="/example/rdd-fuzzy_files/figure-html/check-outcome-fuzzy-discontinuity-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>There’s still a visible gap at 70, but there are people who did and did not use the program on both sides of the cutoff.</p>
<p>Another way to look at this is to make a sort of histogram that shows the probability of being in the tutoring program at different entrance exam scores. 100% of people who score between 25 and 50 on the exam used tutoring, so that’s good, but then the probability of tutoring drops to ≈80ish% up until the cutpoint at 70. After 70, there’s a 10–15% chance of using tutoring if you’re above the threshold.</p>
<p>If this were a sharp design, every single bar to the left of the cutpoint would be 100% and every single bar to the right would be 0%, but that’s not the case here. The probability of tutoring changes at the cutpoint, but it’s not 100% perfect.</p>
<pre class="r"><code># This fun code uses cut() to split the entrance exam column into distinct
# categories (0-5, 5-10, 10-15, etc.). You&#39;ll see some strange syntax in the
# categories it creates: (70, 75]. These ranges start with ( and end with ] for
# a reason: ( means the range *does not* include the number, while ] means that
# the range *does* include the number. (70, 75] thus means 71-75. You can
# reverse that with an argument to cut() so taht it would do [70, 75), which
# means 70-74.
tutoring_with_bins &lt;- tutoring %&gt;% 
  mutate(exam_binned = cut(entrance_exam, breaks = seq(0, 100, 5))) %&gt;% 
  # Group by each of the new bins and tutoring status
  group_by(exam_binned, tutoring) %&gt;% 
  # Count how many people are in each test bin + used/didn&#39;t use tutoring
  summarize(n = n()) %&gt;% 
  # Make this summarized data wider so that there&#39;s a column for tutoring and no tutoring
  pivot_wider(names_from = &quot;tutoring&quot;, values_from = &quot;n&quot;, values_fill = 0) %&gt;% 
  rename(tutor_yes = `TRUE`, tutor_no = `FALSE`) %&gt;% 
  # Find the probability of tutoring in each bin by taking 
  # the count of yes / count of yes + count of no
  mutate(prob_tutoring = tutor_yes / (tutor_yes + tutor_no))

# Plot this puppy
ggplot(tutoring_with_bins, aes(x = exam_binned, y = prob_tutoring)) +
  geom_col() +
  geom_vline(xintercept = 8.5) +
  labs(x = &quot;Entrance exam score&quot;, y = &quot;Proportion of people participating in program&quot;)</code></pre>
<p><img src="/example/rdd-fuzzy_files/figure-html/fuzzy-binned-1.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="measuring-a-fuzzy-gap" class="section level2">
<h2>Measuring a fuzzy gap</h2>
<p>So how do we actually measure this gap, given all the compliance issues? Recall from Session 12 that <em>instruments</em> let us isolate causal effects for just compliers: they let us find <a href="/example/cace/">the complier average causal effect, or CACE</a>.</p>
<p>But what should we use as an instrument? Do we use something weird like <a href="http://ftp.iza.org/dp7725.pdf">the Scrabble score of people’s names</a>? Something <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3715610">overused like rainfall</a>?</p>
<p>No! In this case, the instrument is fairly easy and straightforward: we create a variable that indicates if someone is above or below the threshold. That’s all. This variable essentially measures <em>what should have happened</em> rather than what actually happened.</p>
<p>Surprisingly, it meets all the qualifications of an instrument too:</p>
<ul>
<li><strong>Relevance</strong> (<span class="math inline">\(Z \rightarrow X\)</span> and <span class="math inline">\(\operatorname{Cor}(Z, X) \neq 0\)</span>): The cutoff causes access to the tutoring program.</li>
<li><strong>Exclusion</strong> (<span class="math inline">\(Z \rightarrow X \rightarrow Y\)</span> and <span class="math inline">\(Z \nrightarrow Y\)</span> and <span class="math inline">\(\operatorname{Cor}(Z, Y | X) = 0\)</span>): The cutoff causes exit exam scores <em>only through</em> the tutoring program.</li>
<li><strong>Exogeneity</strong> (<span class="math inline">\(U \nrightarrow Z\)</span> and <span class="math inline">\(\operatorname{Cor}(Z, U) = 0\)</span>): Unobserved confounders between the tutoring program and exit exam scores are unrelated to the cutoff.</li>
</ul>
<div id="fuzzy-parametric-estimation" class="section level3">
<h3>Fuzzy parametric estimation</h3>
<p>Let’s make an instrument! We’ll also center the running variable just like we did with sharp regression discontinuity:</p>
<pre class="r"><code>tutoring_centered &lt;- tutoring %&gt;% 
  mutate(entrance_centered = entrance_exam - 70,
         below_cutoff = entrance_exam &lt;= 70)
tutoring_centered</code></pre>
<pre><code>## # A tibble: 1,000 x 7
##       id entrance_exam tutoring tutoring_text exit_exam entrance_centered below_cutoff
##    &lt;dbl&gt;         &lt;dbl&gt; &lt;lgl&gt;    &lt;chr&gt;             &lt;dbl&gt;             &lt;dbl&gt; &lt;lgl&gt;       
##  1     1          92.4 FALSE    No tutor           78.1            22.4   FALSE       
##  2     2          72.8 FALSE    No tutor           58.2             2.77  FALSE       
##  3     3          53.7 TRUE     Tutor              62.0           -16.3   TRUE        
##  4     4          98.3 FALSE    No tutor           67.5            28.3   FALSE       
##  5     5          69.7 TRUE     Tutor              54.1            -0.288 TRUE        
##  6     6          68.1 TRUE     Tutor              60.1            -1.93  TRUE        
##  7     7          86.0 FALSE    No tutor           73.1            16.0   FALSE       
##  8     8          85.7 TRUE     Tutor              76.7            15.7   FALSE       
##  9     9          85.9 FALSE    No tutor           57.8            15.9   FALSE       
## 10    10          89.5 FALSE    No tutor           79.9            19.5   FALSE       
## # … with 990 more rows</code></pre>
<p>Now we have a new column named <code>below_cutoff</code> that we’ll use as an instrument. Most of the time this will be the same as the <code>tutoring</code> column, since most people are compliers. But some people didn’t comply, like person 8 here who was <em>not</em> below the cutoff but still used the tutoring program.</p>
<p>Before using the instrument, let’s first run a model that assumes the cutoff is sharp. As we did with <a href="https://evalf20.classes.andrewheiss.com/example/rdd/#parametric-estimation">the sharp parametric analysis</a>, we’ll include two explanatory variables:</p>
<p><span class="math display">\[
\text{Exit exam} = \beta_0 + \beta_1 \text{Entrance exam score}_\text{centered} + \beta_2 \text{Tutoring program} + \epsilon
\]</span></p>
<p>We’ll use a bandwidth of 10:</p>
<pre class="r"><code># Bandwidth ±10
model_sans_instrument &lt;- lm(exit_exam ~ entrance_centered + tutoring,
                            data = filter(tutoring_centered,
                                          entrance_centered &gt;= -10 &amp; 
                                            entrance_centered &lt;= 10))
tidy(model_sans_instrument)</code></pre>
<pre><code>## # A tibble: 3 x 5
##   term              estimate std.error statistic   p.value
##   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)         59.3      0.503     118.   9.75e-313
## 2 entrance_centered    0.511    0.0665      7.69 1.17e- 13
## 3 tutoringTRUE        11.5      0.744      15.4  1.77e- 42</code></pre>
<p>Here, the coefficient for <code>tutoringTRUE</code> shows the size of the jump, which is 11.5. This means that participating in the tutoring program <em>causes</em> an increase of 11.5 points on the final exam for people in the bandwidth.</p>
<p><strong>BUT THIS IS WRONG.</strong> This is <em>not</em> a sharp discontinuity, so we can’t actually do this. Instead, we need to run a 2SLS model that includes our instrument in the first stage, which will then remove the endogeneity built into participation in the program. We’ll estimate this set of models:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{Tutoring program}} &amp;= \gamma_0 + \gamma_1 \text{Entrance exam score}_\text{centered} + \gamma_2 \text{Below cutoff} + \omega \\
\text{Exit exam} &amp;= \beta_0 + \beta_1 \text{Entrance exam score}_\text{centered} + \beta_2 \widehat{\text{Tutoring program}} + \epsilon
\end{aligned}
\]</span></p>
<p>We could manually run the first stage model, generate predicted <code>tutoring</code> and then use those predicted values in the second stage model <a href="/example/iv/">like we did in the instrumental variables example</a>, but that’s tedious and nobody wants to do all that work. We’ll use <code>iv_robust()</code> from the <strong>estimatr</strong> package instead.</p>
<pre class="r"><code>model_fuzzy &lt;- iv_robust(
  exit_exam ~ entrance_centered + tutoring | entrance_centered + below_cutoff,
  data = filter(tutoring_centered, entrance_centered &gt;= -10 &amp; entrance_centered &lt;= 10)
)
tidy(model_fuzzy)</code></pre>
<pre><code>##                term estimate std.error statistic  p.value conf.low conf.high  df   outcome
## 1       (Intercept)    60.14     1.018      59.1 9.7e-200    58.14     62.14 400 exit_exam
## 2 entrance_centered     0.44     0.099       4.4  1.4e-05     0.24      0.63 400 exit_exam
## 3      tutoringTRUE     9.74     1.912       5.1  5.4e-07     5.98     13.50 400 exit_exam</code></pre>
<p>Based on this model, using <code>below_cutoff</code> as an instrument, we can see that the coefficient for <code>tutoringTRUE</code> is different now! It’s 9.74, which means that the tutoring program <em>causes</em> an average increase of 9.74 points on the final exam <strong>for compliers in the bandwidth</strong>.</p>
<p>Notice that last caveat. Because we’re working with regression discontinuity, we’re estimating a local average treatment effect (LATE) for people in the bandwidth. Because we’re working with instrumental variables, we’re estimating the LATE for compliers only. That means our fuzzy regression discontinuity result here is <em>doubly robust</em>.</p>
<p>If we compare this fuzzy result to the sharp result, we can see a sizable difference:</p>
<pre class="r"><code># gof_omit here will omit goodness-of-fit rows that match any of the text. This
# means &#39;contains &quot;IC&quot; OR contains &quot;Low&quot; OR contains &quot;Adj&quot; OR contains &quot;p.value&quot;
# OR contains &quot;statistic&quot; OR contains &quot;se_type&quot;&#39;. Basically we&#39;re getting rid of
# all the extra diagnostic information at the bottom
modelsummary(list(&quot;No instrument (wrong)&quot; = model_sans_instrument,
                  &quot;Fuzzy RD (bw = 10)&quot; = model_fuzzy),
             gof_omit = &#39;IC|Log|Adj|p\\.value|statistic|se_type&#39;,
             stars = TRUE) %&gt;% 
  # Add a background color to row 5
  row_spec(5, background = &quot;#F5ABEA&quot;)</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
No instrument (wrong)
</th>
<th style="text-align:center;">
Fuzzy RD (bw = 10)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:center;">
59.274***
</td>
<td style="text-align:center;">
60.141***
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(0.503)
</td>
<td style="text-align:center;">
(1.018)
</td>
</tr>
<tr>
<td style="text-align:left;">
entrance_centered
</td>
<td style="text-align:center;">
0.511***
</td>
<td style="text-align:center;">
0.437***
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(0.067)
</td>
<td style="text-align:center;">
(0.099)
</td>
</tr>
<tr>
<td style="text-align:left;background-color: #F5ABEA !important;">
tutoringTRUE
</td>
<td style="text-align:center;background-color: #F5ABEA !important;">
11.484***
</td>
<td style="text-align:center;background-color: #F5ABEA !important;">
9.741***
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(0.744)
</td>
<td style="text-align:center;">
(1.912)
</td>
</tr>
<tr>
<td style="text-align:left;">
Num.Obs.
</td>
<td style="text-align:center;">
403
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
R2
</td>
<td style="text-align:center;">
0.373
</td>
<td style="text-align:center;">
0.365
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
119.103
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
N
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
403
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border:0;" colspan="100%">
<sup></sup> * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01
</td>
</tr>
</tfoot>
</table>
<p>We can (and should!) <a href="https://evalf20.classes.andrewheiss.com/example/rdd/#parametric-estimation">do all the other things that we talked about in the regression discontinuity example</a>, like modifying the bandwidth, adding polynomial terms, and so forth to see how robust the finding is. But we won’t do any of that here.</p>
</div>
<div id="fuzzy-nonparametric-estimation" class="section level3">
<h3>Fuzzy nonparametric estimation</h3>
<p>We can also use nonparametric methods to measure the size of the fuzzy gap at the cutoff. We’ll use <code>rdrobust()</code> just like we <a href="https://evalf20.classes.andrewheiss.com/example/rdd/#nonparametric-estimation-1">did in the sharp example</a>. The only difference is that we have to add one extra argument. That’s it!</p>
<p>To do fuzzy estimation with <code>rdrobust()</code>, use the <code>fuzzy</code> argument to specify the treatment column (or <code>tutoring</code> in our case). <strong>Importantly</strong> (and confusingly! this took me waaaaay too long to figure out!), you <strong><em>do not</em></strong> need to specify an instrument (or even create one!). All you need to specify is the column that indicates treatment status—<code>rdrobust()</code> will do all the above/below-the-cutoff instrument stuff behind the scenes for you.</p>
<pre class="r"><code>rdrobust(y = tutoring$exit_exam, x = tutoring$entrance_exam, 
         c = 70, fuzzy = tutoring$tutoring) %&gt;% 
  summary()</code></pre>
<pre><code>## Call: rdrobust
## 
## Number of Obs.                 1000
## BW type                       mserd
## Kernel                   Triangular
## VCE method                       NN
## 
## Number of Obs.                 238         762
## Eff. Number of Obs.            170         347
## Order est. (p)                   1           1
## Order bias  (q)                  2           2
## BW est. (h)                 12.985      12.985
## BW bias (b)                 19.733      19.733
## rho (h/b)                    0.658       0.658
## Unique Obs.                    238         762
## 
## =============================================================================
##         Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       
## =============================================================================
##   Conventional     9.683     1.893     5.116     0.000     [5.973 , 13.393]    
##         Robust         -         -     4.258     0.000     [5.210 , 14.095]    
## =============================================================================</code></pre>
<p>That’s all! Using nonparametric methods, with a triangular kernel and a bandwidth of ±12.96, the causal effect of the tutoring program for compliers in the bandwidth is 9.683.</p>
<p>We can (and should!) <a href="https://evalf20.classes.andrewheiss.com/example/rdd/#nonparametric-estimation">do all the other nonparametric robustness checks that we talked about in the regression discontinuity example</a>, like modifying the bandwidth (ideal, half, double) and messing with the kernel (uniform, triangular, Epanechnikov) to see how robust the finding is. But again, we won’t do any of that here.</p>
</div>
</div>
